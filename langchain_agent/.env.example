# Environment Configuration Example
# Copy this file to .env and adjust values as needed

# PostgreSQL Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=langchain_agent

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# LLM Model Selection (any Ollama model)
LLM_MODEL=gpt-oss:20b
LLM_TEMPERATURE=0

# Embeddings Model (must match vector dimension in config)
EMBEDDINGS_MODEL=nomic-embed-text:latest

# Reranker Model Options:
#   - Qwen/Qwen3-Reranker-8B (default, state-of-the-art, 16GB)
#   - BAAI/bge-reranker-v2-m3 (small, fast, 440MB)
#   - BAAI/bge-reranker-v2-large (larger, more accurate)
RERANKER_MODEL=Qwen/Qwen3-Reranker-8B

# Retrieval Configuration
RETRIEVER_K=4                    # Final documents to return
RETRIEVER_FETCH_K=30             # Candidates to fetch before reranking
RETRIEVER_LAMBDA_MULT=0.25       # Balance of lexical (0.0) vs semantic (1.0)

# Reranker Configuration
ENABLE_RERANKING=true            # Always enabled for best quality
RERANKER_FETCH_K=15              # Candidates to rerank
RERANKER_TOP_K=4                 # Final documents after reranking

# Query Evaluation
ENABLE_QUERY_EVALUATION=true     # Dynamic lambda_mult based on query type
QUERY_EVAL_TIMEOUT_MS=3000       # Timeout for query evaluation

# Conversation Settings
DEFAULT_THREAD_ID=default_thread
ENABLE_COMPACTION=true           # Smart context management for long conversations
MAX_CONTEXT_TOKENS=3000          # Conservative estimate for context window

# Logging
LOG_LEVEL=INFO                   # Options: DEBUG, INFO, WARNING, ERROR

# Advanced (rarely changed)
VECTOR_DIMENSION=768             # nomic-embed-text produces 768-dim vectors
VECTOR_INDEX_TYPE=ivfflat        # Fast approximate search
VECTOR_SIMILARITY_METRIC=cosine  # Similarity metric

